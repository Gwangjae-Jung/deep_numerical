{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up the experiment\n",
    "\n",
    "\n",
    "Zero-shot superresolution: From `(32, 32)` to `(64, 64)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  os, sys, time\n",
    "from    pathlib             import  Path\n",
    "import  pickle\n",
    "import  yaml\n",
    "\n",
    "import  numpy       as  np\n",
    "import  torch\n",
    "from    torch.utils.data            import  TensorDataset, DataLoader\n",
    "\n",
    "from    matplotlib.axes     import  Axes\n",
    "import  matplotlib.pyplot   as      plt\n",
    "\n",
    "path_script = Path(os.getcwd())\n",
    "path_work   = path_script.parent.parent\n",
    "sys.path.append(str(path_work))\n",
    "\n",
    "from    deep_numerical.utils     import  GaussianNormalizer\n",
    "from    deep_numerical.utils     import  count_parameters\n",
    "from    deep_numerical.utils     import  relative_error\n",
    "from    deep_numerical.utils     import  ones, repeat, velocity_grid\n",
    "from    deep_numerical.neuralop  import  SFNO\n",
    "from    deep_numerical.numerical import  distribution   as  dist\n",
    "\n",
    "from    train_utils     import  load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Load the configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prefix = \"20250625_172116\"\n",
    "with open(str( path_script / train_prefix / \"config_train.yaml\" )) as f:\n",
    "    config      = yaml.load(f, Loader = yaml.FullLoader)\n",
    "    _exp        = config['experiment']\n",
    "    _model      = config['sfno']\n",
    "    _data       = config['pde_dataset']\n",
    "DIMENSION = len(_model['n_modes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Set the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key: experiment\n",
    "RANDOM_SEED:    int = _exp['seed']\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "print(f\"Random seed: {RANDOM_SEED}\")\n",
    "\n",
    "BATCH_SIZE:     int             = _exp['batch_size']\n",
    "TEST_SIZE:      int             = None\n",
    "DEVICE:         torch.device    = torch.device(f\"cuda:3\")\n",
    "\n",
    "# key: train_info\n",
    "TRAIN_RESOLUTION:   int = _data['resolution']\n",
    "def get_path(model_appendix: str='') -> str:\n",
    "    return f\"{train_prefix}/sfno{model_appendix}_boltzmann{TRAIN_RESOLUTION}_res{TRAIN_RESOLUTION}\"\n",
    "\n",
    "# key: pde_dataset\n",
    "TEST_PATH:      Path    = Path(_data['path_test'])\n",
    "\n",
    "NUM_TIME_STEPS = _data['num_time_steps']\n",
    "VHS_COEFF = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SFNO(**_model)\n",
    "model.load_state_dict(torch.load(get_path()+\".pth\", weights_only=True))\n",
    "model.to(DEVICE)\n",
    "print(f\"The number of the parameters\\n>>> {count_parameters(model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4. Report the train history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rel_error__data:  list[float] = []\n",
    "train_rel_error__cons:  list[float] = []\n",
    "val_rel_error__data:    list[float] = []\n",
    "val_rel_error__cons:    list[float] = []\n",
    "train_time:         float       = 0.0\n",
    "\n",
    "# Train history\n",
    "with open(f\"{get_path()}.pickle\", \"rb\") as f:\n",
    "    custom_train_history = pickle.load(f)\n",
    "    train_rel_error__data:  torch.Tensor = \\\n",
    "        torch.tensor(custom_train_history['train_rel_error'], dtype = torch.float)\n",
    "    train_rel_error__cons:  torch.Tensor = \\\n",
    "        torch.tensor(custom_train_history['train_rel_error_cons'], dtype = torch.float)\n",
    "    val_rel_error__data:    torch.Tensor = \\\n",
    "        torch.tensor(custom_train_history['val_rel_error'], dtype = torch.float)\n",
    "    val_rel_error__cons:    torch.Tensor = \\\n",
    "        torch.tensor(custom_train_history['val_rel_error_cons'], dtype = torch.float)\n",
    "    train_time:         float = \\\n",
    "        custom_train_history['train_time']\n",
    "\n",
    "# Number of epochs\n",
    "NUM_TRAIN_EPOCHS = train_rel_error__data.numel()\n",
    "_epoch_list = torch.arange(NUM_TRAIN_EPOCHS) + 1\n",
    "\n",
    "# Print training data\n",
    "print(\n",
    "    \"Minimum training relative error (data, cons) >>>\",\n",
    "    f\"{train_rel_error__data.min().item():.4e}, {train_rel_error__cons.min().item():.4e}\",\n",
    ")\n",
    "print(\n",
    "    \"Minimum validation relative error (data, cons) >>>\",\n",
    "    f\"{val_rel_error__data.min().item():.4e}, {val_rel_error__cons.min().item():.4e}\",\n",
    ")\n",
    "print(f\"Training time: {train_time:.2f} second(s).\")\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 1, figsize=(16, 6))\n",
    "axes.set_title(\"Relative error\")\n",
    "### Train data\n",
    "axes.plot(\n",
    "    _epoch_list, train_rel_error__data,\n",
    "    c='r', linewidth=1, linestyle='-',\n",
    "    label='data'\n",
    ")\n",
    "axes.plot(\n",
    "    _epoch_list, train_rel_error__cons,\n",
    "    c='r', linewidth=1, linestyle='--',\n",
    "    label='cons'\n",
    ")\n",
    "### Validation data\n",
    "axes.plot(\n",
    "    _epoch_list, val_rel_error__data,\n",
    "    c='g', linewidth=1, linestyle='-',\n",
    "    label='val data'\n",
    ")\n",
    "axes.plot(\n",
    "    _epoch_list, val_rel_error__cons,\n",
    "    c='g', linewidth=1, linestyle='--',\n",
    "    label='val cons'\n",
    ")\n",
    "axes.set_xlabel(\"Epoch\")\n",
    "axes.set_ylabel(\"Relative error\")\n",
    "axes.set_yscale(\"log\")\n",
    "axes.legend()\n",
    "axes.set_title(f\"Training history of {get_path()}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Instantiate the storages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_in    = 'data'\n",
    "test_data:  dict[str, torch.Tensor]= {\n",
    "    k_in:       None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Load the normalizers and the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizers\n",
    "normalizer: dict[str, GaussianNormalizer] = {k_in: None}\n",
    "_normalizer = torch.load(f\"{get_path()}_normalizer.pth\", weights_only=False)\n",
    "for k in normalizer.keys():\n",
    "    normalizer[k] = _normalizer[k]\n",
    "    normalizer[k].to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "test_data, test_info = load_data(TEST_PATH, 64, VHS_COEFF, 1)\n",
    "V_MAX           = test_info['v_max']\n",
    "WHERE_CLOSED    = test_info['v_where_closed']\n",
    "test_data['data'] = test_data['data'][:, :NUM_TIME_STEPS].to(DEVICE)\n",
    "\n",
    "for k in normalizer.keys():\n",
    "    test_data[k] = normalizer[k].encode(test_data[k])\n",
    "\n",
    "TEST_SIZE   = test_data[k_in].shape[0]\n",
    "RESOLUTION        = test_data[k_in].shape[-2]\n",
    "\n",
    "print(f\"The size of the test dataset >>>\", TEST_SIZE, sep=' ')\n",
    "print(f\"The shape of the test dataset >>>\", test_data[k_in].shape, sep=' ')\n",
    "print('-'*50)\n",
    "print(f\"The number of time steps >>>\", NUM_TIME_STEPS, sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Instantiate dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(test_data[k_in])\n",
    "\"\"\"The `TensorDataset` class, which saves the *normalized* dataset.\"\"\"\n",
    "\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\"\"\"The `DataLoader` class, which loads the *normalized* dataset (`test_dataset`).\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the initial conditions\n",
    "pred_list      = [\n",
    "    normalizer[k_in].decode(test_data[k_in][:, 0]).cpu()\n",
    "]\n",
    "\"\"\"Saves *decoded* predictions.\"\"\"\n",
    "traj_list = [\n",
    "    normalizer[k_in].decode(test_data[k_in][:, 0]).cpu()\n",
    "]\n",
    "\"\"\"Saves *decoded* target data.\"\"\"\n",
    "test_rel_error_list = [\n",
    "    relative_error(pred_list[0], traj_list[0]).cpu()\n",
    "]\n",
    "\"\"\"Saves the relative errors between the *decoded* predictions and targets.\"\"\"\n",
    "\n",
    "for k in normalizer.keys():\n",
    "    normalizer[k].to(DEVICE)\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "elapsed_time = time.time()\n",
    "with torch.no_grad():\n",
    "    val_rel_error:  float   = 0\n",
    "    with torch.no_grad():\n",
    "        for traj, in test_loader:\n",
    "            traj:   torch.Tensor  = traj.to(DEVICE)\n",
    "            num_trajectories    = len(traj)\n",
    "            pred = traj[:, 0]\n",
    "            \n",
    "            for idx in range(NUM_TIME_STEPS - 1):\n",
    "                # Time-marching (in the scaled space)\n",
    "                pred = model.forward(pred)\n",
    "                # Descale data\n",
    "                pred_decoded    = normalizer[k_in].decode(pred)\n",
    "                target_decoded  = normalizer[k_in].decode(traj[:, idx+1])\n",
    "                # Loss 1 - Data-driven loss\n",
    "                _test_rel_error = relative_error(pred_decoded, target_decoded, p=2.0)\n",
    "                # Backup\n",
    "                pred_list.append(pred_decoded.cpu())\n",
    "                traj_list.append(target_decoded.cpu())\n",
    "                test_rel_error_list.append(_test_rel_error.cpu())\n",
    "elapsed_time = time.time() - elapsed_time\n",
    "traj_list           = torch.stack(traj_list, dim=1)\n",
    "pred_list           = torch.stack(pred_list, dim=1)\n",
    "test_rel_error_list = torch.stack(test_rel_error_list, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rel_error = relative_error(pred_list, traj_list)\n",
    "idx_evaluation = 50\n",
    "assert max_rel_error.ndim==1\n",
    "b_best = torch.argmin(test_rel_error_list[:, idx_evaluation])\n",
    "b = torch.argmax(test_rel_error_list[:, idx_evaluation])\n",
    "\n",
    "print(f\"* Elapsed time: {elapsed_time:.2f} second(s)\")\n",
    "print(f\"* Relative error (p=2):\")\n",
    "print(f\"  - Average: {test_rel_error_list[:, idx_evaluation].mean():.4e}\")\n",
    "print(f\"  - std.dev: {test_rel_error_list[:, idx_evaluation].std():.4e}\")\n",
    "print(f\"  - Best case:  {test_rel_error_list[b_best, idx_evaluation]:.4e} (at instance {b_best})\")\n",
    "print(f\"  - Worst case: {test_rel_error_list[b, idx_evaluation]:.4e} (at instance {b})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plot some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_t_idx = [0, 10, 20, 30, 40, 50]\n",
    "\n",
    "newshape = (\n",
    "    TEST_SIZE, NUM_TIME_STEPS,\n",
    "    *ones(DIMENSION), *repeat(RESOLUTION, DIMENSION),\n",
    "    1\n",
    ")\n",
    "v_grid = velocity_grid(DIMENSION, RESOLUTION, V_MAX)\n",
    "\n",
    "extent_v = (-V_MAX, V_MAX, V_MAX, -V_MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_list = pred_list[:, 0].reshape((TEST_SIZE, *ones(DIMENSION), *repeat(RESOLUTION, DIMENSION), 1))\n",
    "initial_moments = dist.compute_moments_homogeneous(init_list, v_grid)\n",
    "equi_list = dist.maxwellian_homogeneous(v_grid, *initial_moments)\n",
    "deviance = relative_error(init_list, equi_list).flatten()\n",
    "\n",
    "b_most_deviated = torch.argmax(deviance)\n",
    "print(f\"Most deviated initial condition: Instance {b_most_deviated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. The worst prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_side_length = 5.0\n",
    "fig, axes = plt.subplots(3, len(random_t_idx), figsize=(len(random_t_idx)*(_side_length+0.1), 3*_side_length))\n",
    "for cnt, idx in enumerate(random_t_idx):\n",
    "    axes[0, cnt].set_title(f\"Ground truth\\n(Instance {b}, time index {idx})\")\n",
    "    axes[1, cnt].set_title(f\"Prediction\\n(Instance {b}, time index {idx})\")\n",
    "    axes[2, cnt].set_title(f\"Difference \\n(Instance {b})\")\n",
    "    _t = traj_list[b, idx].reshape((RESOLUTION, RESOLUTION))\n",
    "    _p = pred_list[b, idx].reshape((RESOLUTION, RESOLUTION))\n",
    "    fig.colorbar(axes[0, cnt].imshow(_t, extent=extent_v))\n",
    "    fig.colorbar(axes[1, cnt].imshow(_p, extent=extent_v))\n",
    "    fig.colorbar(axes[2, cnt].imshow((_t-_p), extent=extent_v))\n",
    "    axes[0, cnt].set_xlabel(r\"$v_x$\")\n",
    "    axes[0, cnt].set_ylabel(r\"$v_y$\")\n",
    "    axes[1, cnt].set_xlabel(r\"$v_x$\")\n",
    "    axes[1, cnt].set_ylabel(r\"$v_y$\")\n",
    "    axes[2, cnt].set_xlabel(r\"$v_x$\")\n",
    "    axes[2, cnt].set_ylabel(r\"$v_y$\")\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "\n",
    "__pred_list = pred_list.reshape(newshape)\n",
    "__one_pred  = __pred_list[b_most_deviated]\n",
    "\n",
    "print(f\"The shape of a trajectory: {__one_pred.shape}\")\n",
    "fig, axes = dist.plot_quantities_homogeneous(\n",
    "    __one_pred,\n",
    "    v_grid,\n",
    "    arr_t = 0.1*torch.arange(NUM_TIME_STEPS),\n",
    "    dim=2,\n",
    "    mode='plot',\n",
    "    scatter_size=10,\n",
    ")\n",
    "fig.suptitle(f\"Instance {b_most_deviated}\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Relative error of the test dataset\")\n",
    "plt.xlabel(\"Time index\")\n",
    "plt.ylabel(\"Relative error (p=2)\")\n",
    "plt.plot(test_rel_error_list[b_most_deviated].cpu(), linewidth=1, linestyle='-')\n",
    "# plt.scatter(25*torch.ones(deviance.shape), deviance, s=10, c='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GJ2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
