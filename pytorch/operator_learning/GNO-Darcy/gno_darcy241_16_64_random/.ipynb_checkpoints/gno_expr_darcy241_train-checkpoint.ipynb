{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  os, time\n",
    "from    pathlib             import  Path\n",
    "from    tqdm.notebook       import  tqdm\n",
    "import  pickle\n",
    "\n",
    "import  numpy                       as  np\n",
    "import  torch\n",
    "from    torch                       import  nn, optim\n",
    "from    torch_geometric.data        import  Data\n",
    "from    torch_geometric.loader      import  DataLoader\n",
    "\n",
    "import  yaml\n",
    "\n",
    "from    custom_modules.utils                import  GaussianNormalizer, npzReader\n",
    "from    custom_modules.utils                import  RandomGridGenerator\n",
    "from    custom_modules.pytorch.neuralop     import  GNOLite\n",
    "from    custom_modules.pytorch.ref_neuralop import  KernelNN\n",
    "from    custom_modules.pytorch.torch_utils  import  count_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Load the configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config_train.yaml\") as f:\n",
    "    config = yaml.load(f, Loader = yaml.FullLoader)\n",
    "    _exp   = config['experiment']\n",
    "    _data  = config['pde_dataset']\n",
    "    _graph = config['graph']\n",
    "    _gno   = config['gno']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Set the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE Training and data preprocess\n",
    "\n",
    "\n",
    "BATCH_SIZE      = _exp['batch_size']\n",
    "NUM_EPOCHS      = _exp['num_epochs']\n",
    "LEARNING_RATE   = _exp['learning_rate']\n",
    "TRAIN_SIZE      = _exp['train_size']\n",
    "VAL_SIZE        = _exp['val_size']\n",
    "\n",
    "\n",
    "RESOLUTION      = _data['resolution']\n",
    "TRAIN_PATH      = Path(_data['path'])\n",
    "__RANDOM_CHOICE = np.random.choice(1024, TRAIN_SIZE + VAL_SIZE, replace = False)\n",
    "TRAIN_MASK      = __RANDOM_CHOICE[:TRAIN_SIZE]\n",
    "VAL_MASK        = __RANDOM_CHOICE[-VAL_SIZE:]\n",
    "\n",
    "\n",
    "DOWNSAMPLE      = _data['downsample']\n",
    "GRID            = (RESOLUTION - 1) // DOWNSAMPLE + 1\n",
    "NUM_NODES       = GRID ** 2\n",
    "\n",
    "\n",
    "RADIUS_TRAIN    = _graph['radius']\n",
    "SAMPLE_SIZE     = _graph['sample_size']\n",
    "NUM_SAMPLING    = _graph['num_sampling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of the parameters in the custom GNO\n",
      ">>> 332065\n",
      "The number of the parameters in the reference GNO\n",
      ">>> 332065\n",
      "GraphNeuralOperatorLite(\n",
      "    lift:       MLP(layer=(6, 32), bias=True, activation=relu),\n",
      "    hidden:     GraphKernelLayer(node_dim=32, kernel_layer=MLP(layer=(6, 256, 256, 1024), bias=True, activation=relu))\n",
      "                x 6)\n",
      "                )\n",
      "    projection: MLP(layer=(32, 1), bias=True, activation=relu),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "### NOTE Model instantiation\n",
    "\n",
    "\n",
    "GNO_SOURCE  = (\"custom\", \"reference\")\n",
    "GNO_INDEX   = _gno['gno_index']\n",
    "\n",
    "GNO_LIST= (\n",
    "    GNOLite(\n",
    "                in_channels         = _gno['in_channels'],\n",
    "                hidden_channels     = _gno['hidden_channels'],\n",
    "                out_channels        = _gno['out_channels'],\n",
    "                edge_channels       = _gno['edge_channels'],\n",
    "                n_layers            = _gno['n_layers'],\n",
    "                lift_layer          = _gno['lift_layer'],\n",
    "                kernel_layer        = _gno['kernel_layer'],\n",
    "                project_layer       = _gno['project_layer'],\n",
    "                activation          = _gno['activation'],\n",
    "            ).cuda(),\n",
    "    KernelNN(\n",
    "                in_width        = _gno['in_channels'],\n",
    "                ker_in          = _gno['edge_channels'],\n",
    "                width           = _gno['hidden_channels'],\n",
    "                ker_width       = _gno['kernel_layer'][0],  # `KernelNN` uses a 2-layer MLP\n",
    "                depth           = _gno['n_layers'],\n",
    "            ).cuda()\n",
    ")\n",
    "\n",
    "print(f\"The number of the parameters in the custom GNO\\n>>> {   count_parameters(GNO_LIST[0])}\")\n",
    "print(f\"The number of the parameters in the reference GNO\\n>>> {count_parameters(GNO_LIST[1])}\")\n",
    "\n",
    "gno: GNOLite | KernelNN = GNO_LIST[GNO_INDEX]\n",
    "print(gno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Instantiate the storages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data: dict[str, torch.Tensor]= {\n",
    "    'coeff':    None,\n",
    "    'Kcoeff':   None,\n",
    "    'Kcoeff_x': None,\n",
    "    'Kcoeff_y': None,\n",
    "    'sol':      None,\n",
    "}\n",
    "val_data: dict[str, torch.Tensor]= {\n",
    "    'coeff':    None,\n",
    "    'Kcoeff':   None,\n",
    "    'Kcoeff_x': None,\n",
    "    'Kcoeff_y': None,\n",
    "    'sol':      None,\n",
    "}\n",
    "\n",
    "\n",
    "normalizer: dict[str, GaussianNormalizer] = {\n",
    "    'coeff':    None,\n",
    "    'Kcoeff':   None,\n",
    "    'Kcoeff_x': None,\n",
    "    'Kcoeff_y': None,\n",
    "    'sol':      None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Load the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea211695e6e74a5c8612ecbe9c8bf366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing the train data: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d91488dcc68478f8d1d1db84fb49443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing the validation data: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train data\n",
    "reader = npzReader(TRAIN_PATH)\n",
    "for cnt, k in tqdm(enumerate(train_data.keys()), desc = \"Preprocessing the train data\"):\n",
    "    # Step 1. Load data\n",
    "    train_data[k] = torch.from_numpy(reader.get_field(k)[TRAIN_MASK, ::DOWNSAMPLE, ::DOWNSAMPLE])\n",
    "    train_data[k] = train_data[k].flatten(-1)\n",
    "    train_data[k] = train_data[k].type(torch.float)\n",
    "    \n",
    "    # Step 2. Normalize data\n",
    "    normalizer[k] = GaussianNormalizer(train_data[k])\n",
    "    train_data[k] = normalizer[k].encode(train_data[k])\n",
    "\n",
    "\n",
    "# Validation data\n",
    "for cnt, k in tqdm(enumerate(val_data.keys()), desc = \"Preprocessing the validation data\"):\n",
    "    # Step 1. Load data\n",
    "    val_data[k] = torch.from_numpy(reader.get_field(k)[VAL_MASK, ::DOWNSAMPLE, ::DOWNSAMPLE])\n",
    "    val_data[k] = val_data[k].flatten(-1)\n",
    "    val_data[k] = val_data[k].type(torch.float)\n",
    "    \n",
    "    # Step 2. Normalize data (NOTE: Uses the normalizers for the train dataset)\n",
    "    val_data[k] = normalizer[k].encode(val_data[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Construct graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE Generate a grid to set the node and edge attributes\n",
    "\n",
    "\n",
    "grid_generator  = RandomGridGenerator(\n",
    "                        domain      = [[0., 1.], [0., 1.]],\n",
    "                        grid_size   = [GRID, GRID],\n",
    "                        radius      = RADIUS_TRAIN,\n",
    "                        sample_size = SAMPLE_SIZE\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d7243d7e564ff3bccba446167f42e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686a4121b58f404f9315dd27358db1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NOTE Construct graphs\n",
    "\n",
    "\n",
    "list_train_data, list_test_data = [], []\n",
    "\n",
    "\n",
    "for idx in tqdm(range(TRAIN_SIZE)):\n",
    "    for cnt in range(NUM_SAMPLING):\n",
    "        grid_full_info = grid_generator.full_information()\n",
    "        full_node_index     = grid_full_info['node_index']\n",
    "        full_edge_index     = grid_full_info['edge_index']\n",
    "        full_grid           = grid_full_info['grid']\n",
    "        \n",
    "        grid_sample_info = grid_generator.sample(_return = True)\n",
    "        sample_node_index   = grid_sample_info['sample_node_index']\n",
    "        sample_edge_index   = grid_sample_info['sample_edge_index']\n",
    "        sample_grid         = grid_sample_info['sample_grid']\n",
    "        \n",
    "        _coeff      = train_data[ 'coeff'  ][idx].reshape(NUM_NODES, -1)\n",
    "        _Kcoeff     = train_data[ 'Kcoeff' ][idx].reshape(NUM_NODES, -1)\n",
    "        _Kcoeff_x   = train_data['Kcoeff_x'][idx].reshape(NUM_NODES, -1)\n",
    "        _Kcoeff_y   = train_data['Kcoeff_y'][idx].reshape(NUM_NODES, -1)\n",
    "        # Define the node feature\n",
    "        _x = torch.hstack(\n",
    "            [\n",
    "                sample_grid,\n",
    "                _coeff[sample_node_index],\n",
    "                _Kcoeff[sample_node_index],\n",
    "                _Kcoeff_x[sample_node_index],\n",
    "                _Kcoeff_y[sample_node_index],\n",
    "            ]\n",
    "        )\n",
    "        # Define the node target\n",
    "        _y = train_data['sol'][idx].reshape(NUM_NODES, -1)[sample_node_index]\n",
    "        # Define the edge feature\n",
    "        _edge_attr = torch.hstack(\n",
    "            [\n",
    "                full_grid[sample_edge_index[0]],\n",
    "                full_grid[sample_edge_index[1]],\n",
    "                _coeff[sample_edge_index[0]],\n",
    "                _coeff[sample_edge_index[1]]\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Append the new graph\n",
    "        list_train_data.append(\n",
    "            Data(\n",
    "                x = _x,\n",
    "                y = _y,\n",
    "                edge_index  = sample_edge_index,\n",
    "                edge_attr   = _edge_attr,\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "for idx in tqdm(range(VAL_SIZE)):\n",
    "    for cnt in range(NUM_SAMPLING):\n",
    "        grid_full_info = grid_generator.full_information()\n",
    "        full_node_index     = grid_full_info['node_index']\n",
    "        full_edge_index     = grid_full_info['edge_index']\n",
    "        full_grid           = grid_full_info['grid']\n",
    "        \n",
    "        grid_sample_info = grid_generator.sample(_return = True)\n",
    "        sample_node_index   = grid_sample_info['sample_node_index']\n",
    "        sample_edge_index   = grid_sample_info['sample_edge_index']\n",
    "        sample_grid         = grid_sample_info['sample_grid']\n",
    "        \n",
    "        _coeff      = val_data[ 'coeff'  ][idx].reshape(NUM_NODES, -1)\n",
    "        _Kcoeff     = val_data[ 'Kcoeff' ][idx].reshape(NUM_NODES, -1)\n",
    "        _Kcoeff_x   = val_data['Kcoeff_x'][idx].reshape(NUM_NODES, -1)\n",
    "        _Kcoeff_y   = val_data['Kcoeff_y'][idx].reshape(NUM_NODES, -1)\n",
    "        # Define the node feature\n",
    "        _x = torch.hstack(\n",
    "            [\n",
    "                sample_grid,\n",
    "                _coeff[sample_node_index],\n",
    "                _Kcoeff[sample_node_index],\n",
    "                _Kcoeff_x[sample_node_index],\n",
    "                _Kcoeff_y[sample_node_index],\n",
    "            ]\n",
    "        )\n",
    "        # Define the node target\n",
    "        _y = val_data['sol'][idx].reshape(NUM_NODES, -1)[sample_node_index]\n",
    "        # Define the edge feature\n",
    "        _edge_attr = torch.hstack(\n",
    "            [\n",
    "                full_grid[sample_edge_index[0]],\n",
    "                full_grid[sample_edge_index[1]],\n",
    "                _coeff[sample_edge_index[0]],\n",
    "                _coeff[sample_edge_index[1]]\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Append the new graph\n",
    "        list_test_data.append(\n",
    "            Data(\n",
    "                x = _x,\n",
    "                y = _y,\n",
    "                edge_index  = sample_edge_index,\n",
    "                edge_attr   = _edge_attr,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4. Instantiate dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(list_train_data, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader  = DataLoader(list_test_data,  batch_size = BATCH_SIZE, shuffle = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Initialize the model and instantiate the loss function and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in gno.parameters():\n",
    "    if p.ndim == 1:\n",
    "        nn.init.zeros_(p)\n",
    "    else:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "criterion = nn.MSELoss(reduction = 'mean')\n",
    "optimizer = optim.Adam(params = gno.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ac923111ef4d6f95cb9d1ac5549df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch 1 / 300 ]\n",
      "* train_loss     : 3.3321e+00\n",
      "* train_error    : 2.3033e+00\n",
      "* val_loss       : 2.9354e+00\n",
      "* val_error      : 2.1592e+00\n",
      "[ Epoch 10 / 300 ]\n",
      "* train_loss     : 5.6938e-01\n",
      "* train_error    : 9.5263e-01\n",
      "* val_loss       : 5.4245e-01\n",
      "* val_error      : 9.2748e-01\n",
      "[ Epoch 20 / 300 ]\n",
      "* train_loss     : 3.0987e-01\n",
      "* train_error    : 7.0214e-01\n",
      "* val_loss       : 3.2183e-01\n",
      "* val_error      : 7.1409e-01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m---> 49\u001b[0m         batch: Data \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m         val_pred \u001b[38;5;241m=\u001b[39m gno\u001b[38;5;241m.\u001b[39mforward(batch\u001b[38;5;241m.\u001b[39mx, batch\u001b[38;5;241m.\u001b[39medge_index, batch\u001b[38;5;241m.\u001b[39medge_attr)\n\u001b[0;32m     52\u001b[0m         val_loss \u001b[38;5;241m=\u001b[39m criterion\u001b[38;5;241m.\u001b[39mforward(val_pred, batch\u001b[38;5;241m.\u001b[39my)\n",
      "File \u001b[1;32mc:\\Users\\GJ2\\anaconda3\\envs\\torch\\lib\\site-packages\\torch_geometric\\data\\data.py:376\u001b[0m, in \u001b[0;36mBaseData.cuda\u001b[1;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# Some PyTorch tensor like objects require a default value for `cuda`:\u001b[39;00m\n\u001b[0;32m    375\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m device\n\u001b[1;32m--> 376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\GJ2\\anaconda3\\envs\\torch\\lib\\site-packages\\torch_geometric\\data\\data.py:340\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstores:\n\u001b[1;32m--> 340\u001b[0m     \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\GJ2\\anaconda3\\envs\\torch\\lib\\site-packages\\torch_geometric\\data\\storage.py:201\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrecursive_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\GJ2\\anaconda3\\envs\\torch\\lib\\site-packages\\torch_geometric\\data\\storage.py:895\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[1;34m(data, func)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m--> 895\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mPackedSequence):\n\u001b[0;32m    897\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(data)\n",
      "File \u001b[1;32mc:\\Users\\GJ2\\anaconda3\\envs\\torch\\lib\\site-packages\\torch_geometric\\data\\data.py:376\u001b[0m, in \u001b[0;36mBaseData.cuda.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# Some PyTorch tensor like objects require a default value for `cuda`:\u001b[39;00m\n\u001b[0;32m    375\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m device\n\u001b[1;32m--> 376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    377\u001b[0m                   \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_history = {\n",
    "    'train_loss':   [],\n",
    "    'train_error':  [],\n",
    "    'val_loss':     [],\n",
    "    'val_error':    [],\n",
    "    'train_time':   0.0,\n",
    "}\n",
    "normalizer['sol'].cuda()\n",
    "\n",
    "elapsed_time = time.time()\n",
    "for epoch in tqdm(range(1, NUM_EPOCHS + 1)):\n",
    "    # NOTE: Train\n",
    "    if True:\n",
    "        gno.train()\n",
    "        _train_time = time.time()\n",
    "        train_epoch_loss:  torch.Tensor = 0\n",
    "        train_epoch_error: torch.Tensor = 0\n",
    "        for batch in train_loader:\n",
    "            batch: Data = batch.cuda()\n",
    "            train_pred = gno.forward(batch.x, batch.edge_index, batch.edge_attr)           \n",
    "            train_loss = criterion.forward(train_pred, batch.y)\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_epoch_loss = train_epoch_loss + (\n",
    "                train_loss\n",
    "            ) * len(batch)\n",
    "            train_pred  = normalizer['sol'].decode(train_pred)\n",
    "            batch.y     = normalizer['sol'].decode(batch.y)\n",
    "            train_epoch_error = train_epoch_error + (\n",
    "                torch.linalg.norm(train_pred - batch.y) / (1e-8 + torch.linalg.norm(batch.y))\n",
    "            ) * len(batch)\n",
    "        _train_time = time.time() - _train_time\n",
    "        train_history['train_time'] += _train_time\n",
    "        train_epoch_loss    = train_epoch_loss / TRAIN_SIZE\n",
    "        train_epoch_error   = train_epoch_error / TRAIN_SIZE\n",
    "        train_history['train_loss'].append(train_epoch_loss.item())\n",
    "        train_history['train_error'].append(train_epoch_error.item())\n",
    "    \n",
    "    \n",
    "    # NOTE: Validation\n",
    "    if True:\n",
    "        gno.eval()\n",
    "        val_epoch_loss:     torch.Tensor = 0\n",
    "        val_epoch_error:    torch.Tensor = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch: Data = batch.cuda()\n",
    "                \n",
    "                val_pred = gno.forward(batch.x, batch.edge_index, batch.edge_attr)\n",
    "                val_loss = criterion.forward(val_pred, batch.y)\n",
    "                \n",
    "                val_epoch_loss      = val_epoch_loss + val_loss * len(batch)\n",
    "                val_pred = normalizer['sol'].decode(val_pred)\n",
    "                batch.y  = normalizer['sol'].decode(batch.y)\n",
    "                val_epoch_error     = val_epoch_error + (\n",
    "                                            torch.linalg.norm(val_pred - batch.y) / (1e-8 + torch.linalg.norm(batch.y))\n",
    "                                        ) * len(batch)\n",
    "        val_epoch_loss      = val_epoch_loss / VAL_SIZE\n",
    "        val_epoch_error     = val_epoch_error / VAL_SIZE\n",
    "        train_history['val_loss'].append(val_epoch_loss.item())\n",
    "        train_history['val_error'].append(val_epoch_error.item())\n",
    "    \n",
    "    # Report\n",
    "    if True:\n",
    "        if epoch % 10 == 0 or epoch == 1:\n",
    "            print(f\"[ Epoch {epoch} / {NUM_EPOCHS} ]\")\n",
    "            for k in train_history.keys():\n",
    "                if k == \"train_time\":\n",
    "                    continue\n",
    "                print(f\"* {k:15s}: {train_history[k][-1]:.4e}\")\n",
    "    \n",
    "elapsed_time = time.time() - elapsed_time\n",
    "print(f\"Elapsed time: {int(elapsed_time)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. Save the model and the train history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gno.cpu()\n",
    "\n",
    "# Save the model\n",
    "gno_src = GNO_SOURCE[GNO_INDEX]\n",
    "os.makedirs(GNO_SOURCE[GNO_INDEX], exist_ok = True)\n",
    "torch.save(gno.state_dict(), f\"{gno_src}/gno_darcy{RESOLUTION}_res{GRID}.pth\")\n",
    "\n",
    "# Save the normalizer, which will also be used in prediction\n",
    "normalizer['sol'].cpu()\n",
    "torch.save(normalizer, f\"{gno_src}/gno_darcy{RESOLUTION}_res{GRID}_normalizer.pth\")\n",
    "\n",
    "# Save the history\n",
    "with open(f\"{gno_src}/gno_darcy{RESOLUTION}_res{GRID}.pickle\", \"wb\") as f:\n",
    "    pickle.dump(train_history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
