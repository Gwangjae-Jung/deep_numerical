{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0505e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from    typing      import  Callable\n",
    "\n",
    "import  numpy               as      np\n",
    "import  torch\n",
    "import  matplotlib.pyplot   as      plt\n",
    "\n",
    "from    tqdm.notebook       import  tqdm\n",
    "\n",
    "from    kinetic_distribtutions      import  *\n",
    "\n",
    "from    pathlib             import  Path\n",
    "root_dir    = r\"/media/junseung/47a90e46-3a9d-467c-bbee-066752b68532/GWANGJAE\"\n",
    "path_root   = Path(root_dir)\n",
    "path_lib    = path_root / \"python_deep_numerical\"\n",
    "path_data   = path_root / \"datasets\"\n",
    "\n",
    "from    sys         import  path\n",
    "path.append( str(path_lib) )\n",
    "from    pytorch     import  utils\n",
    "from    pytorch.numerical   import  distribution\n",
    "from    pytorch.numerical.solvers     import  FastSM_Boltzmann_VHS\n",
    "\n",
    "dtype:  torch.dtype     = torch.float64\n",
    "device: torch.device    = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dtype_and_device = {'dtype': dtype, 'device': device}\n",
    "__dtype_str = str(dtype).split('.')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0903214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA_T:    float   = 0.1\n",
    "MAX_T:      float   = 1.0\n",
    "NUM_INST:   int     = 2\n",
    "DATA_SIZE:  int     = NUM_INST * int(MAX_T/DELTA_T + 0.1)\n",
    "\n",
    "T1__n_init  = T2__n_init    = T3__n_init    = NUM_INST\n",
    "T1__size    = T2__size      = T3__size      = DATA_SIZE\n",
    "\n",
    "DIMENSION:  int     = 3\n",
    "RESOLUTION: int     = 2**5\n",
    "V_MAX:      float   = 3.0/utils.LAMBDA\n",
    "DELTA_V:    float   = (2*V_MAX) / RESOLUTION\n",
    "V_WHERE_CLOSED: str = 'left'\n",
    "\n",
    "v_grid = utils.velocity_grid(DIMENSION, RESOLUTION, V_MAX, where_closed=V_WHERE_CLOSED, **dtype_and_device)\n",
    "\n",
    "FFT_AXES:   tuple[int] = tuple(range(-(1+DIMENSION), -1))\n",
    "FFT_NORM:   str  = 'forward'\n",
    "\n",
    "VHS_COEFF = 1 / utils.area_of_unit_sphere(DIMENSION)\n",
    "VHS_ALPHA = -2.0\n",
    "\n",
    "sample_q: Callable[[int], tuple[torch.Tensor]] = \\\n",
    "    lambda batch_size: sample_quantities(DIMENSION, batch_size, **dtype_and_device)\n",
    "\n",
    "# Saved information\n",
    "dataset_info: dict[str, object] = {\n",
    "    'dimension':    DIMENSION,\n",
    "    'resolution':   RESOLUTION,\n",
    "    'v_max':        V_MAX,\n",
    "    'vhs_coeff':    VHS_COEFF,\n",
    "    'equation':     'Boltzmann',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db59253d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/junseung/47a90e46-3a9d-467c-bbee-066752b68532/GWANGJAE/python_deep_numerical/pytorch/numerical/solvers/_kernel_modes/boltzmann_VHS.py:239: Warning: For efficient implementation, the kernel modes for the 3-dimensional case should be referred by computing the 2-norms of the addition and subtraction of two input frequencies. Use the method 'compute_integral_indices' of this class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "solver = FastSM_Boltzmann_VHS(\n",
    "    dimension   = DIMENSION,\n",
    "    v_num_grid  = RESOLUTION,\n",
    "    v_max       = V_MAX,\n",
    "    \n",
    "    vhs_coeff   = VHS_COEFF,\n",
    "    vhs_alpha   = VHS_ALPHA,\n",
    "    \n",
    "    **dtype_and_device,\n",
    ")\n",
    "FFT_CONFIG: dict[str, object] = {'s': solver.v_shape, 'dim': solver.v_axes, 'norm': FFT_NORM}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7cfac2",
   "metadata": {},
   "source": [
    "Type 1. Maxwellian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "302c8d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6999339e074e81a9a8dde2dd412af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the input data\n",
      ">>> torch.Size([2, 10, 1, 1, 1, 32, 32, 32, 1])\n",
      "The shape of the output data\n",
      ">>> torch.Size([2, 10, 1, 1, 1, 32, 32, 32, 1]), torch.Size([2, 10, 1, 1, 1, 32, 32, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "T1__data:   list[torch.Tensor]  = []\n",
    "T1__gain:   list[torch.Tensor]  = []\n",
    "T1__loss:   list[torch.Tensor]  = []\n",
    "\n",
    "T1__init: torch.Tensor = distribution.maxwellian_homogeneous(v_grid, *sample_q(T1__n_init))\n",
    "arr_f_1 = T1__init = normalize_density(T1__init, DELTA_V)\n",
    "arr_f_1_fft: torch.Tensor = torch.fft.fftn(arr_f_1, **FFT_CONFIG)\n",
    "\n",
    "for cnt in tqdm(range(T1__size//T1__n_init)):\n",
    "    ##### 1. Save the distribution at the previous time step\n",
    "    T1__data.append(arr_f_1)\n",
    "    ##### 2. Save the collision term at the previous time step\n",
    "    _gain_1_fft = solver.compute_gain_fft(None, arr_f_1_fft)\n",
    "    _loss_1_fft = solver.compute_loss_fft(None, arr_f_1_fft)\n",
    "    gain_1 = torch.real(torch.fft.ifftn(_gain_1_fft, **FFT_CONFIG))\n",
    "    loss_1 = torch.real(torch.fft.ifftn(_loss_1_fft, **FFT_CONFIG))\n",
    "    T1__gain.append(gain_1)\n",
    "    T1__loss.append(loss_1)\n",
    "    ##### 3. Compute the distribution at the current time step\n",
    "    arr_f_1_fft = solver.forward(0.0, arr_f_1_fft, DELTA_T, utils.one_step_RK4_classic)\n",
    "    arr_f_1 = torch.real(torch.fft.ifftn(arr_f_1_fft, **FFT_CONFIG))\n",
    "    \n",
    "T1__data:   torch.Tensor    = torch.stack(T1__data, dim=1).cpu()\n",
    "T1__gain:   torch.Tensor    = torch.stack(T1__gain, dim=1).cpu()\n",
    "T1__loss:   torch.Tensor    = torch.stack(T1__loss, dim=1).cpu()\n",
    "\n",
    "\n",
    "print(f\"The shape of the input data\")\n",
    "print(f\">>> {T1__data.shape}\")\n",
    "print(f\"The shape of the output data\")\n",
    "print(f\">>> {T1__gain.shape}, {T1__loss.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b208ce13",
   "metadata": {},
   "source": [
    "Type 2. Sum of two Maxwellian distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb6abd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3230dedc823c4a9cbd6aefb678c425a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the input data\n",
      ">>> torch.Size([2, 10, 1, 1, 1, 32, 32, 32, 1])\n",
      "The shape of the output data\n",
      ">>> torch.Size([2, 10, 1, 1, 1, 32, 32, 32, 1]), torch.Size([2, 10, 1, 1, 1, 32, 32, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "T2__data:   list[torch.Tensor]  = []\n",
    "T2__gain:   list[torch.Tensor]  = []\n",
    "T2__loss:   list[torch.Tensor]  = []\n",
    "\n",
    "T2__init: torch.Tensor = \\\n",
    "    0.5 * (\n",
    "        distribution.maxwellian_homogeneous(v_grid, *sample_q(T2__n_init))\n",
    "        +\n",
    "        distribution.maxwellian_homogeneous(v_grid, *sample_q(T2__n_init))\n",
    "    )\n",
    "arr_f_2 = T2__init = normalize_density(T2__init, DELTA_V)\n",
    "arr_f_2_fft: torch.Tensor = torch.fft.fftn(arr_f_2, **FFT_CONFIG)\n",
    "\n",
    "for cnt in tqdm(range(T2__size//T2__n_init)):\n",
    "    ##### 1. Save the distribution at the previous time step\n",
    "    T2__data.append(arr_f_2)\n",
    "    ##### 2. Save the collision term at the previous time step\n",
    "    _gain_2_fft = solver.compute_gain_fft(None, arr_f_2_fft)\n",
    "    _loss_2_fft = solver.compute_loss_fft(None, arr_f_2_fft)\n",
    "    gain_2 = torch.real(torch.fft.ifftn(_gain_2_fft, **FFT_CONFIG))\n",
    "    loss_2 = torch.real(torch.fft.ifftn(_loss_2_fft, **FFT_CONFIG))\n",
    "    T2__gain.append(gain_2)\n",
    "    T2__loss.append(loss_2)\n",
    "    ##### 3. Compute the distribution at the current time step\n",
    "    arr_f_2_fft = solver.forward(0.0, arr_f_2_fft, DELTA_T, utils.one_step_RK4_classic)\n",
    "    arr_f_2 = torch.real(torch.fft.ifftn(arr_f_2_fft, **FFT_CONFIG))\n",
    "    \n",
    "T2__data:   torch.Tensor    = torch.stack(T2__data, dim=1).cpu()\n",
    "T2__gain:   torch.Tensor    = torch.stack(T2__gain, dim=1).cpu()\n",
    "T2__loss:   torch.Tensor    = torch.stack(T2__loss, dim=1).cpu()\n",
    "\n",
    "print(f\"The shape of the input data\")\n",
    "print(f\">>> {T2__data.shape}\")\n",
    "print(f\"The shape of the output data\")\n",
    "print(f\">>> {T2__gain.shape}, {T2__loss.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3541f9",
   "metadata": {},
   "source": [
    "Type 3. Perturbed Maxwellian distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a3d8984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__coeffs: torch.Size([2, 13])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1d2ba0c3294234ba78697d195326cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the input data\n",
      ">>> torch.Size([2, 10, 1, 1, 1, 32, 32, 32, 1])\n",
      "The shape of the output data\n",
      ">>> torch.Size([2, 10, 1, 1, 1, 32, 32, 32, 1]), torch.Size([2, 10, 1, 1, 1, 32, 32, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "T3__data:   list[torch.Tensor] = []\n",
    "T3__gain:   list[torch.Tensor] = []\n",
    "T3__loss:   list[torch.Tensor] = []\n",
    "\n",
    "coeffs = sample_noise_quadratic(DIMENSION, V_MAX, T3__n_init, **dtype_and_device)\n",
    "quad = compute_quadratic_polynomial(v_grid, coeffs)\n",
    "quad = quad.reshape(T3__n_init, *utils.ones(DIMENSION), *utils.repeat(RESOLUTION, DIMENSION), 1)\n",
    "\n",
    "assert quad.min()>=-1\n",
    "\n",
    "T3__init: torch.Tensor = \\\n",
    "    distribution.maxwellian_homogeneous(v_grid, *sample_q(T3__n_init)) * \\\n",
    "    (1 + quad)\n",
    "arr_f_3 = T3__init = normalize_density(T3__init, DELTA_V)\n",
    "arr_f_3_fft: torch.Tensor = torch.fft.fftn(arr_f_3, **FFT_CONFIG)\n",
    "\n",
    "for cnt in tqdm(range(T3__size//T3__n_init)):\n",
    "    ##### 1. Save the distribution at the previous time step\n",
    "    T3__data.append(arr_f_3)\n",
    "    ##### 2. Save the collision term at the previous time step\n",
    "    _gain_3_fft = solver.compute_gain_fft(None, arr_f_3_fft)\n",
    "    _loss_3_fft = solver.compute_loss_fft(None, arr_f_3_fft)\n",
    "    gain_3 = torch.real(torch.fft.ifftn(_gain_3_fft, **FFT_CONFIG))\n",
    "    loss_3 = torch.real(torch.fft.ifftn(_loss_3_fft, **FFT_CONFIG))\n",
    "    T3__gain.append(gain_3)\n",
    "    T3__loss.append(loss_3)\n",
    "    ##### 3. Compute the distribution at the current time step\n",
    "    arr_f_3_fft = solver.forward(0.0, arr_f_3_fft, DELTA_T, utils.one_step_RK4_classic)\n",
    "    arr_f_3 = torch.real(torch.fft.ifftn(arr_f_3_fft, **FFT_CONFIG))\n",
    "    \n",
    "T3__data:   torch.Tensor    = torch.stack(T3__data, dim=1).cpu()\n",
    "T3__gain:   torch.Tensor    = torch.stack(T3__gain, dim=1).cpu()\n",
    "T3__loss:   torch.Tensor    = torch.stack(T3__loss, dim=1).cpu()\n",
    "\n",
    "print(f\"The shape of the input data\")\n",
    "print(f\">>> {T3__data.shape}\")\n",
    "print(f\"The shape of the output data\")\n",
    "print(f\">>> {T3__gain.shape}, {T3__loss.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c228a",
   "metadata": {},
   "source": [
    "Merge the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab3e4eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the input data\n",
      ">>> torch.Size([6, 10, 1, 1, 1, 32, 32, 32, 1])\n",
      "The shape of the output data\n",
      ">>> torch.Size([6, 10, 1, 1, 1, 32, 32, 32, 1]), torch.Size([6, 10, 1, 1, 1, 32, 32, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "data    = \\\n",
    "    torch.concatenate((T1__data, T2__data, T3__data), dim=0)\n",
    "gain    = \\\n",
    "    torch.concatenate((T1__gain, T2__gain, T3__gain), dim=0)\n",
    "loss    = \\\n",
    "    torch.concatenate((T1__loss, T2__loss, T3__loss), dim=0)\n",
    "\n",
    "print(f\"The shape of the input data\")\n",
    "print(f\">>> {data.shape}\")\n",
    "print(f\"The shape of the output data\")\n",
    "print(f\">>> {gain.shape}, {loss.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9509410",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_data: dict[str, object] = {\n",
    "    'input_distribution':   data,\n",
    "    'collision_gain':       gain,\n",
    "    'collision_loss':       loss,\n",
    "    \n",
    "    'n_init':           3*NUM_INST,\n",
    "    \n",
    "    'max_t':            MAX_T,\n",
    "    'delta_t':          DELTA_T,\n",
    "    \n",
    "    'resolution':       RESOLUTION,\n",
    "    'v_max':            V_MAX,\n",
    "    'v_where_closed':   V_WHERE_CLOSED,\n",
    "    \n",
    "    'vhs_coeff':    VHS_COEFF,\n",
    "    'vhs_alpha':    VHS_ALPHA,\n",
    "    \n",
    "    'equation':     'Boltzmann',\n",
    "    'dtype_str':    __dtype_str,\n",
    "}\n",
    "file_dir = path_data / __dtype_str\n",
    "file_name = f\"Boltzmann__{DIMENSION}D__res_{str(RESOLUTION).zfill(3)}__alpha_{float(VHS_ALPHA):.1e}.pth\"\n",
    "if not Path.exists(file_dir):\n",
    "    Path.mkdir(file_dir, parents=True)\n",
    "torch.save(saved_data, file_dir/file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a574d3cb",
   "metadata": {},
   "source": [
    "End of file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GJ2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
